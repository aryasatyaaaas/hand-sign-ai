{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AI Sign Language Translator - Training Notebook\n",
                "\n",
                "## Step 1: Install Dependencies\n",
                "Run this cell first. **If it tells you to Restart Runtime, please do so from the Runtime menu!**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install mediapipe tensorflow tensorflowjs opencv-python pandas scikit-learn matplotlib"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Restart Runtime\n",
                "**Runtime > Restart Session** (or Restart Runtime)\n",
                "Then proceed to Step 3."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Setup Data\n",
                "Upload `kaggle.json` or your dataset zip."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "# OPTION A: Using Kaggle API\n",
                "# !mkdir -p ~/.kaggle\n",
                "# !cp kaggle.json ~/.kaggle/\n",
                "# !chmod 600 ~/.kaggle/kaggle.json\n",
                "# !kaggle datasets download -d grassknoted/asl-alphabet\n",
                "# !unzip -q asl-alphabet.zip\n",
                "\n",
                "# OPTION B: Manual Upload (e.g. data.zip)\n",
                "# !unzip -q data.zip"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Process Data (Fixed)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import cv2\n",
                "import mediapipe as mp\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "# ROBUST IMPORT STRATEGY\n",
                "try:\n",
                "    mp_hands = mp.solutions.hands\n",
                "except AttributeError:\n",
                "    try:\n",
                "        import mediapipe.python.solutions.hands as mp_hands\n",
                "    except ImportError:\n",
                "        from mediapipe import solutions\n",
                "        mp_hands = solutions.hands\n",
                "\n",
                "def extract_landmarks(image_path):\n",
                "    try:\n",
                "        with mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.5) as hands:\n",
                "            image = cv2.imread(image_path)\n",
                "            if image is None: return None\n",
                "            results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
                "            if not results.multi_hand_landmarks: return None\n",
                "            lm = []\n",
                "            for l in results.multi_hand_landmarks[0].landmark:\n",
                "                lm.extend([l.x, l.y, l.z])\n",
                "            return lm\n",
                "    except Exception: return None\n",
                "\n",
                "data = []\n",
                "DATA_DIR = \"asl_alphabet_train/asl_alphabet_train\" # CHECK THIS PATH matches your unzipped folder\n",
                "\n",
                "if not os.path.exists(DATA_DIR):\n",
                "    print(f\"Warning: {DATA_DIR} not found. please check the file browser on the left.\")\n",
                "else:\n",
                "    classes = sorted(os.listdir(DATA_DIR))\n",
                "    print(f\"Processing {len(classes)} classes\")\n",
                "\n",
                "    for label in classes:\n",
                "        class_dir = os.path.join(DATA_DIR, label)\n",
                "        if os.path.isdir(class_dir):\n",
                "            # Processing limited images for speed. Remove [:100] to process all.\n",
                "            images = [img for img in os.listdir(class_dir) if img.endswith(('.jpg', '.jpeg', '.png'))][:100] \n",
                "            \n",
                "            for img_name in images:\n",
                "                path = os.path.join(class_dir, img_name)\n",
                "                lm = extract_landmarks(path)\n",
                "                if lm:\n",
                "                    data.append(lm + [label])\n",
                "\n",
                "    columns = [f'{c}_{i}' for i in range(21) for c in ['x', 'y', 'z']] + ['label']\n",
                "    df = pd.DataFrame(data, columns=columns)\n",
                "    df.to_csv('landmarks.csv', index=False)\n",
                "    print(\"Data extracted to landmarks.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "if not os.path.exists('landmarks.csv'):\n",
                "    print(\"Error: landmarks.csv not found. Did Step 4 run?\")\n",
                "else:\n",
                "    df = pd.read_csv('landmarks.csv')\n",
                "    X = df.iloc[:, :-1].values\n",
                "    y = df.iloc[:, -1].values\n",
                "\n",
                "    label_encoder = LabelEncoder()\n",
                "    y_encoded = label_encoder.fit_transform(y)\n",
                "    classes = label_encoder.classes_\n",
                "    print(\"Classes:\", classes)\n",
                "\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
                "\n",
                "    model = tf.keras.models.Sequential([\n",
                "        tf.keras.layers.Dense(128, activation='relu', input_shape=(63,)),\n",
                "        tf.keras.layers.Dropout(0.2),\n",
                "        tf.keras.layers.Dense(64, activation='relu'),\n",
                "        tf.keras.layers.Dense(len(classes), activation='softmax')\n",
                "    ])\n",
                "\n",
                "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
                "    model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
                "    model.save('model.h5')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Download Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!tensorflowjs_converter --input_format=keras model.h5 tfjs_model\n",
                "!zip -r tfjs_model.zip tfjs_model\n",
                "from google.colab import files\n",
                "files.download('tfjs_model.zip')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}